{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1W53FCQ80weGtyNPLYLkx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Matrix Factorisation Workshop using the Surprise Library"],"metadata":{"id":"h_KDJS04cRCk"}},{"cell_type":"code","metadata":{"id":"JSJNjz2pVNgs"},"source":["pip install scikit-surprise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ev8-T6kBVWWE","executionInfo":{"status":"ok","timestamp":1673601937012,"user_tz":-480,"elapsed":683,"user":{"displayName":"Barry Shepherd","userId":"14632529924177760561"}}},"source":["from surprise import KNNBasic\n","from surprise import KNNWithMeans\n","from surprise import SVD\n","from surprise import SVDpp\n","from surprise import NMF\n","from surprise import Dataset\n","from surprise import accuracy\n","from surprise import Reader\n","from surprise.model_selection import train_test_split\n","from surprise.model_selection import cross_validate\n","\n","import os\n","import numpy as np\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHgjXkx2VgpU"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BpseN-ZPVisr","executionInfo":{"status":"ok","timestamp":1673604505317,"user_tz":-480,"elapsed":513,"user":{"displayName":"Barry Shepherd","userId":"14632529924177760561"}}},"source":["#load the movielens 100K dataset\n","file = \"/content/drive/My Drive/recsys/u_data.csv\"\n","ratings_df = pd.read_csv(file)\n","ratings_df.columns = ['user_id','item_id','rating','datetime']\n","ratings_df.drop('datetime',axis=1,inplace=True)\n","\n"," # convert to surprise format\n","reader = Reader(rating_scale=(1,5)) # assumes datafile contains: user, item, ratings (in this order)\n","data = Dataset.load_from_df(ratings_df, reader)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVBuaUyjV8IO"},"source":["# split data into training and test sets\n","trainset, testset  = train_test_split(data, test_size=0.1)  # select 10% of rating events (10% of 100K ~ 10K)\n","len(testset) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMuGtwraV84a"},"source":["# select one of the Surprise matrix factorisation algorithms and fit a model\n","\n","algo = SVD(n_factors = 50) # simon funks algorithm, default is 100 factors\n","#algo = SVDpp(n_factors = 50) # an extension of SVD that handles implicit ratings\n","#algo = NMF(n_factors = 50) # non negative matrix factorisation\n","\n","algo.fit(trainset) # build the model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_Fa9JUTWN8K"},"source":["# pick a target user to make recommendations for\n","rawuid = 3 \n","\n","# get a list of all unseen items for all users, then extract the target user\n","unseen = trainset.build_anti_testset() \n","targetonly = list()\n","for ruid, riid, r in unseen:  \n","    if (ruid == rawuid):\n","        targetonly.append((rawuid, riid, r))\n","\n","print(\"number of unseen items=\", len(targetonly)) # the number of unseen items for the target user (if this is zero then go back and pick another target user)\n","targetonly[0:4] # show the first 4 of the target users unseen items, the rating shown is the user mean (user bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHsWSdUOW1M-","executionInfo":{"status":"ok","timestamp":1673602230950,"user_tz":-480,"elapsed":515,"user":{"displayName":"Barry Shepherd","userId":"14632529924177760561"}}},"source":["# function to get the topN recommendations for each user\n","# by ranking the unseen items by their predicted rating \n","# input is the rating predictions\n","# output is a dictionary where keys are (raw) userids and \n","# values are lists of tuples: [(raw item id, pred.rating),...] \n","# see https://surprise.readthedocs.io/en/stable/FAQ.html\n","\n","from collections import defaultdict\n","\n","def get_top_n(predictions, n=10):\n","    # First map the predictions to each user.\n","    top_n = defaultdict(list)\n","    for uid, iid, true_r, est, _ in predictions:\n","        top_n[uid].append((iid, est))  \n","    # Then sort the predictions for each user and retrieve the k highest ones.\n","    for uid, user_ratings in top_n.items():\n","        user_ratings.sort(key=lambda x: x[1], reverse=True) # sort on predicted rating\n","        top_n[uid] = user_ratings[:n]\n","    return top_n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"wN8CYaOjWcAJ"},"source":["# make rating predictions and recommendations for the target   \n","predictions = algo.test(targetonly)\n","recs = get_top_n(predictions, n=10)\n","recs  # a list of (itemID, predicted rating) pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfWUrWURW8S1"},"source":["# to show the recommendations along with the movie names\n","# we first load the movie titles and create a dict to map movie id to title\n","file = \"/content/drive/My Drive/recsys/u_item.csv\"\n","titles = pd.read_csv(file, dtype=str)\n","titlemap = dict(zip(titles['movie id'],titles['movie name']))\n","\n","# now show the recommendations using the  movie names\n","for user,rlist in recs.items(): \n","    for rawiid, rat in rlist:\n","        print(rat, rawiid, titlemap[str(rawiid)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AfZLIYijY91h"},"source":["# compute MAE for the testset rating predictions\n","# how does this compare with the best MAE's found in workshop2 and workshop3A?\n","preds = algo.test(testset)\n","accuracy.mae(preds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zn9M0ydBZaOD"},"source":["# to help understand how predictions are made when using matrix factorisation we can \n","# compute the rating prediction ourselves from the factorised matrices and the biases: pu,qi,bu,bi\n","\n","# first we examine (a sample) of the User and Item preference matrix\n","print(algo.pu[0:10,0:10])\n","print(algo.qi[0:10,0:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTTBmGzsZnP1"},"source":["# now examine the learned biases (these are useful for cold-start users)\n","print(\"userbias:\",algo.bu[0:4]) # sample of user biases\n","print(\"itembias:\",algo.bi[0:4]) # sample of item biases\n","print(\"global bias:\",algo.default_prediction())# the global mean rating"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xLLoVdaZuBT"},"source":["# now examine the data for the target user & target item\n","# you can pick any item, but pick one of the items recommended above for easy comparison\n","\n","rawuid = 3  # pick the same user as above\n","rawiid = 408 # pick one of the items that was recommended above for this user\n","\n","# convert to innerids\n","uid = trainset.to_inner_uid(rawuid)\n","iid = trainset.to_inner_iid(rawiid)\n","print(\"target user preferences:\\n\", algo.pu[uid,])\n","print(\"target item preferences:\\n\", algo.qi[iid,])\n","print(\"target user bias:\", algo.bu[uid])\n","print(\"target item bias:\", algo.bi[iid])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV9W2yIgarei"},"source":["# manually compute the prediction, this should agree with the output from algo.predict() and algo.test()\n","# scroll back up to see the prediction made using algo.test()\n","pred = algo.default_prediction() + algo.bu[uid] + algo.bi[iid] + sum(algo.pu[uid,] * algo.qi[iid,]) \n","pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5LbY4KvbgVz"},"source":["# Workshop 3B: \n","\n","Using the Book Crossings (BX) dataset, try to find the best value for n_factors (the number of latent features) when using the SVD algorithm.\n","\n","Use all explict book ratings (no need to subsample). Make sure you set the correct ratings range (in Reader) when loading the data"]},{"cell_type":"code","metadata":{"id":"qOeUR0WpNn0e"},"source":["# paste/type in code here to load the data and create the training and test sets......\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpmW8uyzbfoW"},"source":["# NOTE: after loading the data and creating training and test sets you can\n","# explore different number of latent factor using the below code \n","# (adjust the factor list as required)\n","for f in [10,20,30,40,50,60,70,80,90,100,200,500]:\n","    algo = SVD(n_factors = f)\n","    algo.fit(trainset)\n","    preds = algo.test(testset)\n","    print(f, \" \", end=\"\")\n","    accuracy.mae(preds)"],"execution_count":null,"outputs":[]}]}